# configs/train_config.yaml

# Model configuration
model:
  type: random_forest
  random_state: 42

# Model hyperparameters
hyperparameters:
  logistic_regression:
    C: 1.0
    max_iter: 1000
    penalty: l2
    solver: lbfgs
  
  random_forest:
    n_estimators: 100
    max_depth: null
    min_samples_split: 2
    min_samples_leaf: 1
    max_features: sqrt
  
  decision_tree:
    max_depth: null
    min_samples_split: 2
    min_samples_leaf: 1
    criterion: gini
  
  adaboost:
    n_estimators: 50
    learning_rate: 1.0
    algorithm: SAMME.R
  
  gradient_boosting:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 3
    min_samples_split: 2
    subsample: 1.0
  
  voting_classifier:
    voting: soft
    estimators:
      - gradient_boosting
      - logistic_regression
      - adaboost

# Training configuration
training:
  tune_hyperparameters: false
  test_size: 0.2
  random_state: 42
  stratify: true

# Paths
paths:
  data:
    input: data/processed/preprocessed_data.npy  # DVC-tracked
    raw: data/raw  # DVC-tracked
    processed: data/processed  # DVC-tracked
  models:
    output_dir: models  # Local storage + MLflow artifacts

# DVC configuration
dvc:
  remote: origin  # DagsHub remote
  data_version: v1.0
  track_models: false  # Use MLflow for models

# MLflow configuration
mlflow:
  tracking_uri: null  # null = local mlruns/, or set to DagsHub URL
  experiment_name: telecom-churn-prediction
  run_name_prefix: null  # null = auto-generate, or set custom prefix
  artifact_location: null  # null = use default (mlruns/), or set custom
  log_models: true  # Log models to MLflow
  log_artifacts: true  # Log additional artifacts (plots, etc.)
  tags:
    project: telecom-churn
    team: ml-team
    environment: development
  autolog: false  # Use manual logging for control

# Hyperparameter tuning grids
tuning_grids:
  random_forest:
    n_estimators: [50, 100, 200]
    max_depth: [10, 20, 30, null]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: [sqrt, log2]
  
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1, 10, 100]
    penalty: [l1, l2]
    solver: [liblinear, saga]
  
  gradient_boosting:
    n_estimators: [50, 100, 200]
    learning_rate: [0.01, 0.1, 0.2]
    max_depth: [3, 5, 7]
    min_samples_split: [2, 5, 10]
    subsample: [0.8, 0.9, 1.0]

# Cross-validation settings
cross_validation:
  cv_folds: 5
  scoring: accuracy
  n_jobs: -1
  verbose: 1
# configs/train_config.yaml (Version 3: After MLflow - FINAL VERSION)

# Model configuration
model:
  type: random_forest
  random_state: 42

# Model hyperparameters
hyperparameters:
  logistic_regression:
    C: 1.0
    max_iter: 1000
    penalty: l2
    solver: lbfgs
  
  random_forest:
    n_estimators: 100
    max_depth: null
    min_samples_split: 2
    min_samples_leaf: 1
    max_features: sqrt
  
  decision_tree:
    max_depth: null
    min_samples_split: 2
    min_samples_leaf: 1
    criterion: gini
  
  adaboost:
    n_estimators: 50
    learning_rate: 1.0
    algorithm: SAMME.R
  
  gradient_boosting:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 3
    min_samples_split: 2
    subsample: 1.0
  
  voting_classifier:
    voting: soft
    estimators:
      - gradient_boosting
      - logistic_regression
      - adaboost

# Training configuration
training:
  tune_hyperparameters: false
  test_size: 0.2
  random_state: 42
  stratify: true

# Paths
paths:
  data:
    input: data/processed/preprocessed_data.npy  # DVC-tracked
    raw: data/raw  # DVC-tracked
    processed: data/processed  # DVC-tracked
  models:
    output_dir: models  # Local storage + MLflow artifacts

# DVC configuration
dvc:
  remote: origin  # DagsHub remote
  data_version: v1.0
  track_models: false  # Use MLflow for models

# MLflow configuration
mlflow:
  tracking_uri: null  # null = local mlruns/, or set to DagsHub URL
  experiment_name: telecom-churn-prediction
  run_name_prefix: null  # null = auto-generate, or set custom prefix
  artifact_location: null  # null = use default (mlruns/), or set custom
  log_models: true  # Log models to MLflow
  log_artifacts: true  # Log additional artifacts (plots, etc.)
  tags:
    project: telecom-churn
    team: ml-team
    environment: development
  autolog: false  # Use manual logging for control

# Hyperparameter tuning grids
tuning_grids:
  random_forest:
    n_estimators: [50, 100, 200]
    max_depth: [10, 20, 30, null]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: [sqrt, log2]
  
  logistic_regression:
    C: [0.001, 0.01, 0.1, 1, 10, 100]
    penalty: [l1, l2]
    solver: [liblinear, saga]
  
  gradient_boosting:
    n_estimators: [50, 100, 200]
    learning_rate: [0.01, 0.1, 0.2]
    max_depth: [3, 5, 7]
    min_samples_split: [2, 5, 10]
    subsample: [0.8, 0.9, 1.0]

# Cross-validation settings
cross_validation:
  cv_folds: 5
  scoring: accuracy
  n_jobs: -1
  verbose: 1
